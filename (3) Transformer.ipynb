{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad32645-8cd4-4b2c-9be6-68bc220d1d73",
   "metadata": {},
   "source": [
    "### Attention Model\n",
    "- Attention: 중요한 feature에 집중\n",
    "- Attention 모델: Decoder 각 예측 시점마다 주어진 전체 Encoder hidden state 중에서 더 중요한 특징에 집중\n",
    "  - Decoder에서는 매 step마다 인코더의 hidden_state을 이용해 dynamic하게 Context vector를 생성하는데, 이때 hidden state 전체 중에서 해당 시점에 예측해야 할 단어와 연관이 깊은 입력 단어를 집중해서 보게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699006d9-975b-4839-9d60-1f89893347b9",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403beb6a-e9fa-4f1c-bfbd-7baba488e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메세지 끄기\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4550bbfe-b416-4895-8aee-dd3cc22eac95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (4.52.4)\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: filelock in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.5)\n",
      "Requirement already satisfied: setuptools in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shinjoohwan/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a85e3e7-2e8c-49f9-a938-6501d911dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52.4\n",
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e5fdcb-ec25-4790-ace5-c81059a0e472",
   "metadata": {},
   "source": [
    "### Transformer Pipeline 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7ae892-4c46-46d6-8d16-b71fcd813b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c6495-8146-4acf-8352-800dc26aa9f3",
   "metadata": {},
   "source": [
    "#### 1. Sequence Classification: 감성 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e62d0993-c781-496b-92d5-a4450ce49c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe40058-9633-47ae-90b0-30afba624836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998656511306763}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9991129040718079}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier(\"I love you\"))\n",
    "print(classifier(\"I hate you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e752c428-57dc-444c-90c8-47177cec0bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998044371604919}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('We are very happy to show you the Transformers library'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01d628cf-4fbe-47c8-a91b-c1854733ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# pre-trained model 선택 가능. multilingual -> 한국어 지원\n",
    "classifier = pipeline('sentiment-analysis', model = \"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d36c7fd0-1096-499c-840b-1a465e551a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.6782801151275635}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier(\"We are very happy to show you the Transform library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c6def4d-8249-411d-80c4-c2f882b56aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '3 stars', 'score': 0.22962135076522827}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier(\"그 영화 지루하고 재미없네.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394b61b-319e-4207-a767-06085cb86c22",
   "metadata": {},
   "source": [
    "#### 2. Unmasking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f43f2e02-bf23-4f6d-8fc7-c19473a5265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# fill-mask: 빠진 내용 채우기\n",
    "unmasker = pipeline('fill-mask', model = 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4852d441-c63d-412e-95c8-278b06a461f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1317753791809082,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': 'hello i am a fashion model.'},\n",
       " {'score': 0.112042136490345,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': 'hello i am a role model.'},\n",
       " {'score': 0.04798121750354767,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': 'hello i am a new model.'},\n",
       " {'score': 0.03963988646864891,\n",
       "  'token': 2449,\n",
       "  'token_str': 'business',\n",
       "  'sequence': 'hello i am a business model.'},\n",
       " {'score': 0.02204621024429798,\n",
       "  'token': 2944,\n",
       "  'token_str': 'model',\n",
       "  'sequence': 'hello i am a model model.'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Mask]에 들어갈 말들을 골라준다\n",
    "unmasker(\"Hello I am a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e1032-2091-4cd9-afde-d0d3cbff1e9a",
   "metadata": {},
   "source": [
    "#### 3. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfd96ab9-4a16-40b5-b383-23a472288675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Question Answering: 먼저 지문을 주고 질문을 하면 지문 내에서 답을 찾아 답변한다.\n",
    "qa = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1a5509d-66b5-48bb-b9e4-5a4b53e9f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지문\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a question answering dataset is the SQuAD dataset, which is entirely based on that task. \n",
    "If you would like to fine-tune a model on a SQuAD task, you may leverage the `run_squad.py`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae5c8d22-d300-4e1a-af32-ef4015eedd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.38024961948394775, 'start': 34, 'end': 95, 'answer': 'the task of extracting an answer from a text given a question'}\n",
      "{'score': 0.5115312337875366, 'start': 147, 'end': 160, 'answer': 'SQuAD dataset'}\n"
     ]
    }
   ],
   "source": [
    "# 질문에 대한 대답을 지문 내에서 찾아 답변\n",
    "# 결과: start: 지문 내에서 답변 시작 위치, end: 지문 내에서 답변 끝 위치, answer: 답변\n",
    "\n",
    "print(qa(question = \"What is extractive question answering\", context = context))\n",
    "print(qa(question = \"What is a good example of a question answering dataset?\", context = context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3108c-cb63-4f74-ade3-c274a2b331e4",
   "metadata": {},
   "source": [
    "#### 4. Text Generation: 문장 생성을 주면 알아서 문장 뒤를 이어 만들어 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20a4dad0-2993-4860-9f48-f4e01f81f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3a84048-1c6b-4f73-8adb-00bf9ca2f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"When the Titanic crashed, I was in the middle of a long day, and I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I'm going to die?' And I was thinking, 'What if I\"}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(\"When the Titanic crashed, I\", max_length = 50, do_sample = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d8087-5dc8-4c92-ae79-20d1ba589eb9",
   "metadata": {},
   "source": [
    "#### 5. Named Entity Recognotion(NER): 단어 형태소 분석처럼 각 단어별 객체명을 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94ceec7d-e513-4fcd-9423-31d74394c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d8c7333-842d-4b46-8194-bc991ce50b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"\"\"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, \n",
    "therefore very close to the Manhattan Bridge which is visible from the window.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2056c157-2799-4604-b437-6170797acc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-ORG', 'score': 0.99957865, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}, {'entity': 'I-ORG', 'score': 0.9909764, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}, {'entity': 'I-ORG', 'score': 0.9982224, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}, {'entity': 'I-ORG', 'score': 0.9994879, 'index': 4, 'word': 'Inc', 'start': 13, 'end': 16}, {'entity': 'I-LOC', 'score': 0.9994344, 'index': 11, 'word': 'New', 'start': 40, 'end': 43}, {'entity': 'I-LOC', 'score': 0.99931955, 'index': 12, 'word': 'York', 'start': 44, 'end': 48}, {'entity': 'I-LOC', 'score': 0.9993794, 'index': 13, 'word': 'City', 'start': 49, 'end': 53}, {'entity': 'I-LOC', 'score': 0.98625815, 'index': 19, 'word': 'D', 'start': 79, 'end': 80}, {'entity': 'I-LOC', 'score': 0.951427, 'index': 20, 'word': '##UM', 'start': 80, 'end': 82}, {'entity': 'I-LOC', 'score': 0.9336593, 'index': 21, 'word': '##BO', 'start': 82, 'end': 84}, {'entity': 'I-LOC', 'score': 0.97616553, 'index': 28, 'word': 'Manhattan', 'start': 114, 'end': 123}, {'entity': 'I-LOC', 'score': 0.9914629, 'index': 29, 'word': 'Bridge', 'start': 124, 'end': 130}]\n"
     ]
    }
   ],
   "source": [
    "# 단어별 객체명을 나열\n",
    "\n",
    "# O, Outside of a named entity\n",
    "# B-MIS, Begining of a miscellaneous entity right after another miscellaneous entity\n",
    "# I-MIS, Miscellaneous entity\n",
    "# B-PER, Beginning of a person's name right after another person's name\n",
    "# I-PER, Person's name\n",
    "# B-ORG, Begining of an organization right after another organization\n",
    "# I-ORG, Organization\n",
    "# B-LOC, Beginning of a location right after another Location\n",
    "# I-Loc, Location\n",
    "\n",
    "# Hu, ##gging: I-ORG(조직명) 인식\n",
    "# New, York : I - LOC(위치) 인식\n",
    "\n",
    "print(nlp(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f90414-c488-4490-8074-450c36fb9686",
   "metadata": {},
   "source": [
    "#### 6. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ea0b4db-d049-4a4b-b6d2-6aed2f86947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba1b5bc2-eb01-42e7-84c7-e1e678f1e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York. A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband. Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other. In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage. Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the 2010 marriage license application, according to court documents. Prosecutors said the marriages were part of an immigration scam. On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further. After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002. All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say. Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages. Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted. The case was referred to the Bronx District Attorney’s Office by Immigration and Customs Enforcement and the Department of Homeland Security’s Investigation Division. Seven of the men are from so‐called \"red‐flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali. Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force. If convicted, Barrientos faces up to four years in prison. Her next court appearance is scheduled for May 18. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ceb757ec-7f60-45cb-ae4a-eb06c0650942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Liana Barrientos pleaded not guilty to two criminal counts of \"offering a false instrument for filing in the first degree\" Prosecutors say the marriages were part of an immigration scam . If convicted, she faces up to four years in prison .'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(ARTICLE, max_length = 130, min_length = 30, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838e107-67fa-4264-afcf-d5e78a1d446a",
   "metadata": {},
   "source": [
    "#### 7. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b54f6b99-c7ef-4f73-b9d5-2be0e50affc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd9b820b-3dff-417f-adb4-555a804ef118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Hugging Face est une entreprise technologique basée à New York et à Paris.'}]\n"
     ]
    }
   ],
   "source": [
    "print(translator(\"Hugging Face is a technology company based in New York and Paris\", max_length = 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e812fc4-8a43-4c55-91d5-b7c9befddea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
